\section{Related Work}

In this section, I review relevant studies that motivate the current research. Prior work on detecting signs of depression from text-based social media posts can be grouped into three main areas: dataset construction and annotation, machine learning and deep learning methodologies, and the use of contextualized language models.

Recent research on detecting signs of depression from social media highlight both the difficulties and opportunities for applying NLP in mental health analysis. A fundamental contribution in this area is presented in \cite{Kayalvizhi_2022_Dataset}. In this work, the authors emphasize the importance of carefully curated data for effective depression detection. They create a labeled dataset by extracting and manually annotating posts from social media platforms, categorizing them into different severity levels of depression based on psycholinguistic indicators. Their analysis revealed distinct language patterns that relate to mental health states. This study addressed a significant gap in annotated resources and provided early performance benchmarks with classic machine learning models such as SVMs and Naive Bayes, which showed moderate success in identifying severity levels.

Following this, the same authors organized a shared task to encourage wider research on this problem \cite{Kayalvizhi_2022_Findings}. Participants used a variety of methods, ranging from traditional feature-based models to more advanced deep learning architectures like LSTMs and transformers. The results showed that deep learning models, especially those fine-tuned on data from the depression domain, achieved better accuracy and F1 scores compared to traditional techniques.

Another significant contribution to the field comes from \cite{Poswiata_2022}, who participated in the LT-EDI shared task with their system. Their work centers on the use of RoBERTa, a highly optimized BERT-based language model, which they fine-tuned specifically for the detection of depressive signals in social media text. Their approach highlighted the benefits of transfer learning: by first training on large general datasets and then fine-tuning on depression-related texts, their model was able to adapt general language knowledge to this challenging and sensitive task. Their system ranked among the top performers in the shared task, showing how pretrained language models, when carefully fine-tuned can outperform other traditional methods for text that contains subtle psychological indicators.

\cite{Naseem_2022} introduced a framework for identifying depression severity on Reddit, emphasizing the importance of moving beyond binary classification by modeling depression as an ordinal task based on clinical standards like the Beck Depression Inventory (BDI). Their approach involved creating a new dataset labeled with four severity levels and developing a hierarchical attention mechanism to capture the progression and intensity of depressive symptoms. By testing on both a public multi-post dataset and a newly collected single-post dataset, their model showed improved accuracy and early detection over existing baselines.

Another notable contribution to depression severity detection comes from \cite{Munoz_2023}, who propose a balanced approach that prioritizes both interpretability and performance through a feature-based framework enhanced with distributional representations. Their work addresses two key limitations of deep learning models: high computational demands and limited transparency. While transformer-based models like BERT often achieve high accuracy, they are resource-intensive and operate as black boxes. In contrast, the authors offer a more scalable and interpretable solution by combining handcrafted linguistic, emotional, and cognitive features with distributional word embeddings, which enables decent performance in resource-constrained or more practical settings.