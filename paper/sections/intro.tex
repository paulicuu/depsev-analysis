\section{Introduction}

The task of processing natural language continues to grow in both importance and popularity among researchers, but everyday users as well, driven by the rapid rise of large language models and the ongoing changes towards a more semantic web. Technologies such as knowledge graphs and contextual embeddings are becoming more essential in the interpretation of human language for machines, as more and more of the web needs to be machine-readable. This area of artificial intelligence stands out due to its direct interaction with users, who not only benefit from its applications, but also contribute to its improvement through feedback and the data they generate.

In recent years, there has been growing interest in using NLP to support mental health analysis, particularly through the examination of social media and online forums. These platforms often serve as safe spaces where people express their thoughts, emotions, and struggles, including experiences related to depression. While identifying whether a post reflects depression is already a complex task, understanding how severe that depression might be is even more of a challenge.

This research addresses the open challenge posed by the RANLP 2025 shared task: Identification of the Severity of Depression in Forum Posts.

The primary research question of this study is to evaluate various feature representations and modeling approaches for improving the identification of depression severity in texts. Specifically, I compare traditional feature extraction methods like TF-IDF with advanced sentence transformer embeddings to understand their relative effectiveness. I also examine the impact of different pre-trained word embeddings, comparing general-domain GloVe vectors to Twitter-specific embeddings within BiLSTM architectures. Finally, I investigate the benefits of domain-adaptive pre-training using masked language modeling on DistilBERT, followed by fine-tuning, to explore how large language models can enhance performance on this specialized task.

In addition to exploring various modeling techniques, with this research I place strong emphasis on data-level experimentation. Rather than using a single dataset, I attempted to construct a comprehensive dataset by merging and standardizing multiple publicly available depression-related corpora. With this I aimed to increase both the volume and diversity of data, helping to improve representation across different severity levels. To further address class imbalances, I applied resampling methods such as minority class oversampling. Additionally, I explored straightforward data augmentation techniques, including synonym replacement to synthetically expand the training set and enhance model generalization.

The content of this research paper is organized as follows: the Related Work section provides an overview of prior research relevant to this study. The Data section describes the dataset preparation, including cleaning and analysis steps. The Methodology section explains the approaches and configurations used throughout the experiments. The Results section presents the experimental findings and compares the performance of different models. Finally, the Conclusion summarizes the key insights and discusses their broader implications.